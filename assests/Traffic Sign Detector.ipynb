{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDER 0\n",
      "FOLDER 1\n",
      "FOLDER 2\n",
      "FOLDER 3\n",
      "FOLDER 4\n",
      "FOLDER 5\n",
      "FOLDER 6\n",
      "FOLDER 7\n",
      "FOLDER 8\n",
      "FOLDER 9\n",
      "FOLDER 10\n",
      "FOLDER 11\n",
      "FOLDER 12\n",
      "FOLDER 13\n",
      "FOLDER 14\n",
      "FOLDER 15\n",
      "FOLDER 16\n",
      "FOLDER 17\n",
      "FOLDER 18\n",
      "FOLDER 19\n",
      "FOLDER 20\n",
      "FOLDER 21\n",
      "FOLDER 22\n",
      "FOLDER 23\n",
      "FOLDER 24\n",
      "FOLDER 25\n",
      "FOLDER 26\n",
      "FOLDER 27\n",
      "FOLDER 28\n",
      "FOLDER 29\n",
      "FOLDER 30\n",
      "FOLDER 31\n",
      "FOLDER 32\n",
      "FOLDER 33\n",
      "FOLDER 34\n",
      "FOLDER 35\n",
      "FOLDER 36\n",
      "FOLDER 37\n",
      "FOLDER 38\n",
      "FOLDER 39\n",
      "FOLDER 40\n",
      "FOLDER 41\n",
      "FOLDER 42\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "target=[]\n",
    "for x in range(0,43):\n",
    "    totfolder=os.listdir(\"E:/Datasets/traffic sign\" + \"/\" + str(x))\n",
    "    for y in totfolder:\n",
    "        image=cv2.imread(\"E:/Datasets/traffic sign\" + \"/\" + str(x) + \"/\" + y)\n",
    "        features.append(image)\n",
    "        target.append(x)\n",
    "    print(\"FOLDER\" , x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=np.array(features)\n",
    "target=np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fea_train, fea_test, tar_train, tar_test = train_test_split(features,target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image = image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6960, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6960,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839, 32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image=image/255\n",
    "\n",
    "    \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train=np.array(list(map(preprocessing,fea_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839, 32, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train=fea_train.reshape(27839, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen=ImageDataGenerator(rotation_range=10,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen.fit(fea_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=dataGen.flow(fea_train,tar_train,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1392"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels=next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 32, 32, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_train = to_categorical(tar_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839, 43)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839, 32, 32, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(60,(3,3),activation=\"relu\",input_shape=(32,32,1)))\n",
    "model.add(Conv2D(60,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(30,(3,3),activation=\"relu\"))\n",
    "model.add(Conv2D(30,(3,3),activation=\"relu\"))\n",
    "model.add(Conv2D(30,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(43,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-9bf4f18d878a>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "1392/1392 [==============================] - 69s 49ms/step - loss: 2.0416 - accuracy: 0.4296\n",
      "Epoch 2/20\n",
      "1392/1392 [==============================] - 69s 49ms/step - loss: 0.7140 - accuracy: 0.7857\n",
      "Epoch 3/20\n",
      "1392/1392 [==============================] - 70s 51ms/step - loss: 0.4684 - accuracy: 0.8550\n",
      "Epoch 4/20\n",
      "1392/1392 [==============================] - 77s 55ms/step - loss: 0.3491 - accuracy: 0.8936\n",
      "Epoch 5/20\n",
      "1392/1392 [==============================] - 73s 52ms/step - loss: 0.2933 - accuracy: 0.9084\n",
      "Epoch 6/20\n",
      "1392/1392 [==============================] - 71s 51ms/step - loss: 0.2529 - accuracy: 0.9221\n",
      "Epoch 7/20\n",
      "1392/1392 [==============================] - 73s 52ms/step - loss: 0.2314 - accuracy: 0.9293\n",
      "Epoch 8/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.2094 - accuracy: 0.9356\n",
      "Epoch 9/20\n",
      "1392/1392 [==============================] - 67s 48ms/step - loss: 0.1877 - accuracy: 0.9414\n",
      "Epoch 10/20\n",
      "1392/1392 [==============================] - 74s 53ms/step - loss: 0.1701 - accuracy: 0.9497\n",
      "Epoch 11/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.1643 - accuracy: 0.9508\n",
      "Epoch 12/20\n",
      "1392/1392 [==============================] - 67s 48ms/step - loss: 0.1505 - accuracy: 0.9542\n",
      "Epoch 13/20\n",
      "1392/1392 [==============================] - 77s 55ms/step - loss: 0.1475 - accuracy: 0.9554\n",
      "Epoch 14/20\n",
      "1392/1392 [==============================] - 77s 55ms/step - loss: 0.1373 - accuracy: 0.9583\n",
      "Epoch 15/20\n",
      "1392/1392 [==============================] - 68s 49ms/step - loss: 0.1351 - accuracy: 0.9589\n",
      "Epoch 16/20\n",
      "1392/1392 [==============================] - 67s 48ms/step - loss: 0.1310 - accuracy: 0.9611\n",
      "Epoch 17/20\n",
      "1392/1392 [==============================] - 67s 48ms/step - loss: 0.1162 - accuracy: 0.9647\n",
      "Epoch 18/20\n",
      "1392/1392 [==============================] - 67s 48ms/step - loss: 0.1230 - accuracy: 0.9636\n",
      "Epoch 19/20\n",
      "1392/1392 [==============================] - 69s 50ms/step - loss: 0.1198 - accuracy: 0.9654\n",
      "Epoch 20/20\n",
      "1392/1392 [==============================] - 69s 49ms/step - loss: 0.1133 - accuracy: 0.9658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x204fbc56dc0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(dataGen.flow(fea_train,tar_train,batch_size=20),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the Model\n"
     ]
    }
   ],
   "source": [
    "model_json=model.to_json()\n",
    "with open(\"verzeoAITraffic.json\",\"w\") as abc:\n",
    "    abc.write(model_json)\n",
    "    abc.close()\n",
    "model.save_weights(\"verzeoAITrafficWeights.h5\")\n",
    "print(\"Save the Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Sucesssfully\n"
     ]
    }
   ],
   "source": [
    "json_file=open(\"verzeoAITraffic.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model=model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"verzeoAITrafficWeights.h5\")\n",
    "print(\"Loaded Model Sucesssfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassName(classNo):\n",
    "    if   classNo == 0: return 'Speed Limit 20 km/h'\n",
    "    elif classNo == 1: return 'Speed Limit 30 km/h'\n",
    "    elif classNo == 2: return 'Speed Limit 50 km/h'\n",
    "    elif classNo == 3: return 'Speed Limit 60 km/h'\n",
    "    elif classNo == 4: return 'Speed Limit 70 km/h'\n",
    "    elif classNo == 5: return 'Speed Limit 80 km/h'\n",
    "    elif classNo == 6: return 'End of Speed Limit 80 km/h'\n",
    "    elif classNo == 7: return 'Speed Limit 100 km/h'\n",
    "    elif classNo == 8: return 'Speed Limit 120 km/h'\n",
    "    elif classNo == 9: return 'No passing'\n",
    "    elif classNo == 10: return 'No passing for vechiles over 3.5 metric tons'\n",
    "    elif classNo == 11: return 'Right-of-way at the next intersection'\n",
    "    elif classNo == 12: return 'Priority road'\n",
    "    elif classNo == 13: return 'Yield'\n",
    "    elif classNo == 14: return 'Stop'\n",
    "    elif classNo == 15: return 'No vechiles'\n",
    "    elif classNo == 16: return 'Vechiles over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17: return 'No entry'\n",
    "    elif classNo == 18: return 'General caution'\n",
    "    elif classNo == 19: return 'Dangerous curve to the left'\n",
    "    elif classNo == 20: return 'Dangerous curve to the right'\n",
    "    elif classNo == 21: return 'Double curve'\n",
    "    elif classNo == 22: return 'Bumpy road'\n",
    "    elif classNo == 23: return 'Slippery road'\n",
    "    elif classNo == 24: return 'Road narrows on the right'\n",
    "    elif classNo == 25: return 'Road work'\n",
    "    elif classNo == 26: return 'Traffic signals'\n",
    "    elif classNo == 27: return 'Pedestrians'\n",
    "    elif classNo == 28: return 'Children crossing'\n",
    "    elif classNo == 29: return 'Bicycles crossing'\n",
    "    elif classNo == 30: return 'Beware of ice/snow'\n",
    "    elif classNo == 31: return 'Wild animals crossing'\n",
    "    elif classNo == 32: return 'End of all speed and passing limits'\n",
    "    elif classNo == 33: return 'Turn right ahead'\n",
    "    elif classNo == 34: return 'Turn left ahead'\n",
    "    elif classNo == 35: return 'Ahead only'\n",
    "    elif classNo == 36: return 'Go straight or right'\n",
    "    elif classNo == 37: return 'Go straight or left'\n",
    "    elif classNo == 38: return 'Keep right'\n",
    "    elif classNo == 39: return 'Keep left'\n",
    "    elif classNo == 40: return 'Roundabout mandatory'\n",
    "    elif classNo == 41: return 'End of no passing'\n",
    "    elif classNo == 42: return 'End of no passing by vechiles over 3.5 metric tons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capt = cv2.VideoCapture(0)\n",
    "capt.set(3,640)\n",
    "capt.set(4,480)\n",
    "capt.set(10,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'capt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d10956bf2c61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcapt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mimagearr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimagearr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagearr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimagearr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagearr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'capt' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message,image=capt.read()\n",
    "    imagearr=np.asarray(image)\n",
    "    imagearr=cv2.resize(imagearr,(32,32))\n",
    "    imagearr=preprocessing(imagearr)\n",
    "    imagearr=imagearr.reshape(1,32,32,1)\n",
    "    predictions=loaded_model.predict(imagearr)\n",
    "    classIndex=loaded_model.predict_classes(imagearr)\n",
    "    cv2.putText(image,\"Class: \",(20,35),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    cv2.putText(image,\"Probability: \",(20,75),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    probabilityValue=np.amax(predictions)\n",
    "    if probabilityValue>0.75:\n",
    "        cv2.putText(image,getClassName(classIndex),(120 , 35),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,str(int(probabilityValue * 100)) + \" %\",( 200,75),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    cv2.imshow(\"Model Prediction\",image)\n",
    "    returnedValue=cv2.waitKey(1)\n",
    "    if returnedValue==ord(\"s\") or returnedValue==ord(\"S\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
